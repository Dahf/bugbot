---
phase: 05-ai-code-fix-agentic-multi-step-code-generation-im-draft-fix-flow
plan: 02
type: execute
wave: 2
depends_on:
  - 05-01
files_modified:
  - src/services/code_fix_service.py
autonomous: true
requirements:
  - GH-04
  - GH-05
  - GH-06

must_haves:
  truths:
    - "CodeFixService clones the repo into a temp directory for local file access"
    - "Claude explores files via tool_runner with read_file, write_file, search_in_repo, list_directory tools"
    - "Each iteration round runs lint check, AI self-review, and CI validation in sequence"
    - "The loop stops after max 3 rounds or when all quality gates pass"
    - "All changed files are committed atomically via GitHubService.commit_files_atomic"
    - "Token usage is tracked per round and as a running total"
    - "A process log records files explored, rounds taken, changes per round, and validation results"
  artifacts:
    - path: "src/services/code_fix_service.py"
      provides: "Agentic code fix orchestrator"
      exports: ["CodeFixService"]
      min_lines: 200
  key_links:
    - from: "src/services/code_fix_service.py"
      to: "anthropic tool_runner API"
      via: "client.beta.messages.tool_runner"
      pattern: "tool_runner"
    - from: "src/services/code_fix_service.py"
      to: "src/services/github_service.py"
      via: "commit_files_atomic, poll_ci_status, get_installation_token"
      pattern: "github_service\\.(commit_files_atomic|poll_ci_status|get_installation_token)"
    - from: "src/services/code_fix_service.py"
      to: "local clone directory"
      via: "asyncio.create_subprocess_exec git clone"
      pattern: "create_subprocess_exec.*git.*clone"
---

<objective>
Create the CodeFixService -- the core agentic AI code generation engine that clones a repo, lets Claude explore and fix code via tool use, validates through lint/self-review/CI, and produces atomic commits.

Purpose: This is the heart of Phase 5. It replaces the old scaffold-only approach with real AI code generation. Claude reads repository source code, generates fix code, and iterates through quality gates (lint, self-review, CI) up to 3 rounds. The result is a clean, validated code fix committed to the feature branch.

Output: New `src/services/code_fix_service.py` with the complete agentic loop.
</objective>

<execution_context>
@C:/Users/silas/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/silas/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-ai-code-fix-agentic-multi-step-code-generation-im-draft-fix-flow/05-RESEARCH.md
@.planning/phases/05-ai-code-fix-agentic-multi-step-code-generation-im-draft-fix-flow/05-01-SUMMARY.md

@src/services/github_service.py
@src/services/ai_analysis.py
@src/config.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create CodeFixService with repo cloning and agentic tool definitions</name>
  <files>src/services/code_fix_service.py</files>
  <action>
Create `src/services/code_fix_service.py` with the CodeFixService class. This task builds the foundation -- clone management, tool definitions, and the initial agentic call.

**Class structure:**

```python
class CodeFixService:
    def __init__(self, api_key, model, max_tokens, max_rounds, max_files, ci_timeout):
        # Store config
        # Create AsyncAnthropic client
        pass
```

**1. Clone management:**
- `async def clone_repo(self, owner, repo, branch, token) -> Path`:
  - Creates temp dir with `tempfile.mkdtemp(prefix=f"bugbot-{owner}-{repo}-")`
  - Runs `git clone --depth 1 --branch {branch} https://x-access-token:{token}@github.com/{owner}/{repo}.git .` in the temp dir
  - Uses `asyncio.create_subprocess_exec` with 120-second timeout
  - Returns the clone dir Path
  - On failure, cleans up the temp dir and raises RuntimeError

- `def cleanup_clone(self, clone_dir: Path)`:
  - Removes the temp directory using `shutil.rmtree` with an `onerror` handler that calls `os.chmod(path, stat.S_IWRITE)` then retries removal. This handles Windows read-only `.git` files (per research Pitfall 3).

**2. Tool definitions (module-level factory function):**
Create a function `_create_tools(clone_dir: Path, max_files: int)` that returns a list of tool functions. Use closures to capture `clone_dir` and a mutable `files_read_count` list (single-element list for mutation in closure).

Tools to define using `@beta_async_tool` decorator:

a. `read_file(path: str) -> str`: Read a file from the cloned repo.
   - Check files_read_count against max_files; return error string if exceeded.
   - Resolve path relative to clone_dir. Validate it exists and is under clone_dir (security: no path traversal).
   - Read with `utf-8` encoding, `errors="replace"`.
   - Truncate to 500 lines if longer, appending truncation note.
   - Increment files_read_count.

b. `write_file(path: str, content: str) -> str`: Write a fix to a file in the working copy.
   - Resolve path relative to clone_dir. Create parent dirs with `mkdir(parents=True, exist_ok=True)`.
   - Write content with `utf-8` encoding.
   - Return confirmation with byte count.
   - Track the path in a `changed_files` set (shared via closure).

c. `search_in_repo(query: str, file_pattern: str = "*") -> str`: Grep for text across repo files.
   - Use `asyncio.create_subprocess_exec` with `grep -rn -i --include {file_pattern} {query} {clone_dir}`.
   - Cap output to 5000 chars. 30-second timeout.
   - Return matches or "No matches found."

d. `list_directory(path: str = ".") -> str`: List files and dirs at a path.
   - Resolve relative to clone_dir. Validate is_dir.
   - Return sorted entries (first 100), prefixed with "d " or "f ".

The factory function also returns the `changed_files` set and `files_read_count` list so the caller can inspect them after the loop.

**3. System prompt builder:**
- `def _build_code_fix_prompt(self, bug: dict, relevant_paths: list[str]) -> str`:
  - Instructs Claude to act as a senior developer fixing a bug.
  - Includes bug details: hash_id, title, description, severity, steps_to_reproduce, ai_root_cause, ai_affected_area, ai_suggested_fix.
  - Lists the initially identified relevant files (from identify_relevant_files) as starting points.
  - Instructs Claude to: (1) read the relevant files, (2) explore related files if needed, (3) write the fix using write_file, (4) keep changes minimal and focused on the reported bug.
  - Tells Claude to return a brief summary of what it changed and why when done.

**4. Single agentic generation round:**
- `async def _run_generation_round(self, bug, clone_dir, tools, round_number) -> dict`:
  - If round_number == 1: use the full system prompt with bug context.
  - If round_number > 1: use a shorter prompt that includes the previous round's feedback (lint errors, self-review issues, CI failures) and asks Claude to fix the issues.
  - Call `self.client.beta.messages.tool_runner(model=self.model, max_tokens=self.max_tokens, tools=tools, messages=[...])`.
  - Call `runner = ...; final_message = await runner.until_done()`.
  - Extract token usage from final_message.
  - Return `{"message": final_message, "usage": {"input_tokens": ..., "output_tokens": ...}}`.

Note: The `messages` parameter must be built carefully. For round 1, it's a single user message with the system prompt context. For subsequent rounds, include the previous conversation context plus a new user message with feedback.

**Important implementation notes:**
- Import `from anthropic import AsyncAnthropic, beta_async_tool` at the top.
- Import `asyncio`, `logging`, `os`, `shutil`, `stat`, `tempfile` from stdlib.
- Import `from pathlib import Path`.
- The service does NOT import discord -- it's a pure service layer. Progress callbacks are handled by the caller.
  </action>
  <verify>
Run `python -c "from src.services.code_fix_service import CodeFixService; print('Import OK')"` to confirm no import errors. Verify the file has `clone_repo`, `cleanup_clone`, `_create_tools`, `_build_code_fix_prompt`, and `_run_generation_round` defined.
  </verify>
  <done>CodeFixService exists with clone management (clone_repo + cleanup_clone with Windows-safe rmtree), 4 tool definitions via @beta_async_tool (read_file, write_file, search_in_repo, list_directory), system prompt builder, and single-round agentic generation via tool_runner.</done>
</task>

<task type="auto">
  <name>Task 2: Add quality gates (lint, self-review, CI) and the main orchestration method</name>
  <files>src/services/code_fix_service.py</files>
  <action>
Extend CodeFixService with quality gate methods and the main orchestration method that ties everything together.

**1. Linter detection and execution:**
- `async def _detect_and_run_linter(self, clone_dir: Path) -> dict`:
  - Detection order (per research Pattern 4):
    a. Check `pyproject.toml` for `[tool.ruff]` or `[tool.ruff.` -> use `ruff check .`
    b. Check config files in order: `ruff.toml`, `.flake8`, `.pylintrc`, `.eslintrc.js`, `.eslintrc.json`, `.eslintrc.yml`, `eslint.config.js`, `eslint.config.mjs`, `Cargo.toml` (cargo clippy), `go.mod` (go vet)
    c. For JS linters, use `npx eslint .` (not bare `eslint`)
  - Before running, check `shutil.which(linter_binary)` to verify the linter is installed. If not found, return `{"linter": linter_name, "output": "Linter not installed on host", "passed": True, "skipped": True}` (per research Pitfall 2).
  - Run via `asyncio.create_subprocess_exec` with 60-second timeout.
  - Capture stdout + stderr, return `{"linter": name, "output": combined_output, "passed": returncode == 0}`.
  - If no linter config found at all: return `{"linter": None, "output": "", "passed": True}`.

**2. AI self-review:**
- `async def _run_self_review(self, bug: dict, changed_files: dict[str, str]) -> dict`:
  - Builds a prompt asking Claude to review the generated fix against 3 criteria (locked decision):
    1. Correctness vs. bug report -- does the fix address the reported bug?
    2. Side effects -- could the change break anything in related code?
    3. Code style consistency -- does the fix match existing codebase conventions?
  - Includes the bug context and the diff of changed files (read original from clone, compare with new content).
  - Calls `self.client.messages.create` (simple call, no tool use needed for review).
  - Asks for JSON response: `{"passed": true/false, "issues": ["issue1", ...], "summary": "..."}`.
  - Parses response. On parse failure, treat as passed with a warning.
  - Returns the parsed dict.
  - Uses self.model and a lower max_tokens (1024) for the review call.

**3. CI polling wrapper:**
- `async def _check_ci(self, github_service, owner, repo, ref, timeout) -> dict`:
  - Delegates to `github_service.poll_ci_status(owner, repo, ref, timeout=timeout)`.
  - This is a thin wrapper that exists so the orchestrator doesn't need to know CI polling details.

**4. Main orchestration method:**
- `async def generate_fix(self, github_service, owner, repo, branch, bug, relevant_paths, progress_callback=None) -> dict`:
  - This is the entry point called by the Draft Fix button handler.
  - `progress_callback` is an async callable `async def callback(message: str)` for posting Discord progress messages. If None, progress is logged only.

  - **Step 1: Clone repo**
    - Get installation token: `token = await github_service.get_installation_token(owner, repo)`
    - Post progress: "Cloning repository..."
    - Clone: `clone_dir = await self.clone_repo(owner, repo, branch, token)`

  - **Step 2: Set up tools and tracking**
    - `tools, changed_files_set, files_read_count = _create_tools(clone_dir, self.max_files)`
    - Initialize process_log: `{"files_explored": [], "rounds": [], "total_tokens": {"input": 0, "output": 0}}`

  - **Step 3: Iteration loop** (try/finally with cleanup_clone in finally)
    - `best_changed_files = {}` -- tracks the best version of changes
    - `feedback = None` -- feedback from previous round's quality gates
    - For `round_num` in `range(1, self.max_rounds + 1)`:
      a. Post progress: f"Generating fix (round {round_num}/{self.max_rounds})..."
      b. Run generation: `result = await self._run_generation_round(bug, clone_dir, tools, round_num, feedback=feedback, relevant_paths=relevant_paths)`
      c. Track tokens: add to process_log totals. Post progress with token counts.
      d. Collect changed files: read all files in `changed_files_set` from clone_dir to get current content. Store as `current_changes = {path: content for path in changed_files_set}`.
      e. `best_changed_files = current_changes` (always keep latest as best attempt)
      f. Record round in process_log: `{"round": round_num, "files_changed": list(changed_files_set), "tokens": result["usage"]}`.

      **Quality gates (in sequence per locked decision):**

      g. **Lint check:**
         - Post progress: "Running lint check..."
         - `lint_result = await self._detect_and_run_linter(clone_dir)`
         - Record in round log.
         - If lint failed: set `feedback = {"type": "lint", "output": lint_result["output"]}`; continue to next round.

      h. **AI self-review:**
         - Post progress: "Running AI self-review..."
         - `review_result = await self._run_self_review(bug, current_changes)`
         - Record in round log.
         - If review found issues: set `feedback = {"type": "self_review", "issues": review_result["issues"]}`; continue to next round.

      i. **CI check (only if changes were pushed):**
         - Commit current changes atomically to the branch: `commit_sha = await github_service.commit_files_atomic(owner, repo, branch, current_changes, f"fix: {bug.get('title', 'bug fix')} (round {round_num})")`
         - Post progress: "Checking CI status..."
         - `ci_result = await self._check_ci(github_service, owner, repo, commit_sha, self.ci_timeout)`
         - Record in round log.
         - If CI failed: set `feedback = {"type": "ci", "details": ci_result["details"]}`; continue to next round.
         - If CI passed or no_ci or timeout: break (we're done).

      j. If all gates passed: break.

    - **Step 4: Final commit** (if not already committed in CI step)
      - If the last round didn't reach CI (broke out at lint or self-review on the final round), commit the best_changed_files atomically.
      - The commit message should be: `f"fix: {bug.get('title', 'bug fix')} (#{bug.get('hash_id', '')})"` -- clean, no round number.

    - **Step 5: Build result**
      - Determine `validation_passed`: True if the final round passed all gates (lint + review + CI).
      - Return dict:
        ```python
        {
            "success": True,
            "changed_files": best_changed_files,  # {path: content}
            "process_log": process_log,
            "rounds_taken": round_num,
            "validation_passed": validation_passed,
            "commit_sha": commit_sha,
        }
        ```

  - **Error handling:**
    - Wrap the entire flow in try/except. On any unrecoverable error, return `{"success": False, "error": str(exc), "process_log": process_log}`.
    - The `finally` block ALWAYS calls `self.cleanup_clone(clone_dir)`.

  - **Important notes:**
    - The `_run_generation_round` method signature should accept `feedback` and `relevant_paths` params to build the appropriate prompt for each round.
    - For round > 1 with feedback, the prompt should include the specific feedback and ask Claude to address the issues while keeping the fix focused.
    - Track `files_explored` in process_log by reading from `files_read_count` and the tool closure state.
  </action>
  <verify>
Run `python -c "from src.services.code_fix_service import CodeFixService; print('Import OK')"` to confirm no import errors. Verify the file has `_detect_and_run_linter`, `_run_self_review`, `_check_ci`, and `generate_fix` methods.
  </verify>
  <done>CodeFixService has the complete agentic loop: generate_fix orchestrates clone -> tool-based generation -> lint -> self-review -> CI -> iterate (up to 3 rounds). Quality gates feed errors back to Claude for correction. Process log tracks all steps. Changed files are committed atomically. Temp directory is always cleaned up.</done>
</task>

</tasks>

<verification>
1. `python -c "from src.services.code_fix_service import CodeFixService"` succeeds
2. CodeFixService has all methods: clone_repo, cleanup_clone, generate_fix, _detect_and_run_linter, _run_self_review, _check_ci, _run_generation_round
3. Tool definitions use @beta_async_tool decorator from anthropic SDK
4. Process log captures files_explored, per-round details, total tokens
5. Clone cleanup handles Windows read-only files via onerror handler
6. Linter detection checks shutil.which before execution
7. generate_fix accepts a progress_callback for Discord progress messages
</verification>

<success_criteria>
A complete CodeFixService that can clone a repo, let Claude explore and fix code via agentic tool use, validate through lint/self-review/CI quality gates, iterate up to 3 rounds, commit atomically, and return a structured result with process log. The service is a pure business-logic layer with no Discord imports -- progress is communicated via callback.
</success_criteria>

<output>
After completion, create `.planning/phases/05-ai-code-fix-agentic-multi-step-code-generation-im-draft-fix-flow/05-02-SUMMARY.md`
</output>
