---
phase: 02-ai-analysis
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/config.py
  - src/models/database.py
  - src/models/bug.py
  - src/services/__init__.py
  - src/services/ai_analysis.py
  - src/utils/embeds.py
  - requirements.txt
  - .env.example
autonomous: true
requirements: [AI-02, AI-04, AI-07]
user_setup:
  - service: anthropic
    why: "Claude AI API for bug report analysis"
    env_vars:
      - name: ANTHROPIC_API_KEY
        source: "Anthropic Console (https://console.anthropic.com/) -> API Keys -> Create Key"

must_haves:
  truths:
    - "AIAnalysisService.analyze_bug() calls Claude API with structured prompt and returns parsed JSON with root_cause, affected_area, severity, suggested_fix, priority, priority_reasoning, and usage"
    - "Analysis results are stored in the bugs table with dedicated columns for each field"
    - "Token usage (input + output) is captured from the API response and stored per analysis"
    - "Priority scoring rubric (P1-P4) is embedded in the system prompt with weighted multi-factor criteria"
    - "build_analysis_embed() produces a colour-coded Discord embed with all analysis fields and token footer"
    - "Summary embed can display a priority badge field when a bug has been analyzed"
  artifacts:
    - path: "src/services/ai_analysis.py"
      provides: "AIAnalysisService class with analyze_bug method"
      min_lines: 80
    - path: "src/utils/embeds.py"
      provides: "build_analysis_embed function and updated build_summary_embed with priority field"
      contains: "build_analysis_embed"
    - path: "src/models/database.py"
      provides: "Updated schema with analysis columns"
      contains: "ai_root_cause"
    - path: "src/models/bug.py"
      provides: "CRUD methods for storing and retrieving analysis results"
      contains: "store_analysis"
    - path: "src/config.py"
      provides: "ANTHROPIC_API_KEY, ANTHROPIC_MODEL, AI_MAX_TOKENS config"
      contains: "ANTHROPIC_API_KEY"
  key_links:
    - from: "src/services/ai_analysis.py"
      to: "anthropic.AsyncAnthropic"
      via: "messages.create with system prompt"
      pattern: "client\\.messages\\.create"
    - from: "src/services/ai_analysis.py"
      to: "message.usage"
      via: "token extraction from API response"
      pattern: "message\\.usage\\.(input|output)_tokens"
    - from: "src/utils/embeds.py"
      to: "SEVERITY_COLORS"
      via: "colour-coded analysis embed sidebar"
      pattern: "SEVERITY_COLORS"
---

<objective>
Build the AI analysis service layer, database schema extensions, and embed builders for Phase 2.

Purpose: Establish the core AI logic (prompt engineering, Claude API integration, JSON response parsing) and data layer (new DB columns, CRUD methods) that the Discord integration plan will wire into button callbacks. This separates AI concerns from Discord UI concerns.

Output: `src/services/ai_analysis.py` (service class), updated `src/models/database.py` (schema), updated `src/models/bug.py` (analysis CRUD), updated `src/utils/embeds.py` (analysis embed + priority badge), updated `src/config.py` (Anthropic config), updated `requirements.txt` and `.env.example`.
</objective>

<execution_context>
@C:/Users/silas/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/silas/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-ai-analysis/02-CONTEXT.md
@.planning/phases/02-ai-analysis/02-RESEARCH.md
@.planning/phases/01-foundation-and-ingestion/01-01-SUMMARY.md
@.planning/phases/01-foundation-and-ingestion/01-02-SUMMARY.md

# Key source files to read before implementing
@src/config.py
@src/models/database.py
@src/models/bug.py
@src/utils/embeds.py
@requirements.txt
@.env.example
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add Anthropic config, extend DB schema, and add analysis CRUD methods</name>
  <files>
    src/config.py
    src/models/database.py
    src/models/bug.py
    requirements.txt
    .env.example
  </files>
  <action>
**1. Update `requirements.txt`** -- add `anthropic>=0.80.0,<1.0.0` to the dependency list.

**2. Update `.env.example`** -- add these new variables with descriptions:
```
# AI Analysis (Phase 2)
ANTHROPIC_API_KEY=your-anthropic-api-key
ANTHROPIC_MODEL=claude-haiku-4-5-20251001   # Optional: override model
AI_MAX_TOKENS=1024                           # Optional: max output tokens per analysis
```

**3. Update `src/config.py`** -- add three new config fields in `__init__`:
- `ANTHROPIC_API_KEY`: Optional (not required). Use `os.getenv("ANTHROPIC_API_KEY")` -- returns `None` if not set. The AI cog will check this at runtime and return a clear error if missing, but we do NOT block bot startup since the bot is useful without AI analysis.
- `ANTHROPIC_MODEL`: Optional with default `"claude-haiku-4-5-20251001"`. Use `os.getenv("ANTHROPIC_MODEL", "claude-haiku-4-5-20251001")`.
- `AI_MAX_TOKENS`: Optional with default `1024`. Use `int(os.getenv("AI_MAX_TOKENS", "1024"))`.

**4. Update `src/models/database.py`** -- extend the SCHEMA string's `bugs` CREATE TABLE to add these columns AFTER the existing `dismissed_by` column:
```sql
priority TEXT,
priority_reasoning TEXT,
ai_root_cause TEXT,
ai_affected_area TEXT,
ai_severity TEXT,
ai_suggested_fix TEXT,
ai_tokens_used INTEGER,
analysis_message_id INTEGER,
analyzed_at TEXT,
analyzed_by TEXT
```
Also add a migration function `migrate_add_analysis_columns(db)` that checks for missing columns and adds them via ALTER TABLE. This handles existing databases that were created with the Phase 1 schema. Call this migration at the end of `setup_database()` after `executescript(SCHEMA)`.

The migration function should:
- Query `PRAGMA table_info(bugs)` to get existing column names
- For each new column, if not present, execute `ALTER TABLE bugs ADD COLUMN <name> <type>`
- This is idempotent -- safe to run multiple times

**5. Update `src/models/bug.py`** -- add a new method `store_analysis` to `BugRepository`:
```python
async def store_analysis(
    self, hash_id: str, analysis: dict, analyzed_by: str
) -> dict | None:
```
This method should:
- Update the bug row with: `priority`, `priority_reasoning`, `ai_root_cause`, `ai_affected_area`, `ai_severity`, `ai_suggested_fix`, `ai_tokens_used` (from `analysis["usage"]["total_tokens"]`), `analyzed_at` (current UTC ISO), `analyzed_by`
- Also set `status = 'triaged'` and `updated_at`
- Insert a status_history entry (old_status -> 'triaged')
- Commit and return the updated bug dict via `get_bug()`

Also add a method `store_analysis_message_id`:
```python
async def store_analysis_message_id(self, hash_id: str, message_id: int) -> None:
```
This stores the Discord message ID of the analysis embed so we can reference it later.

Also add a method `update_priority`:
```python
async def update_priority(
    self, hash_id: str, priority: str, reasoning: str, changed_by: str
) -> dict | None:
```
This updates just the priority and priority_reasoning fields (for manual override). Does NOT change status.
  </action>
  <verify>
- `pip install -r requirements.txt` succeeds (anthropic installs)
- `python -c "from src.config import Config"` imports without error
- `python -c "from src.models.database import SCHEMA; assert 'ai_root_cause' in SCHEMA"` passes
- `python -c "from src.models.bug import BugRepository; assert hasattr(BugRepository, 'store_analysis')"` passes
  </verify>
  <done>Config loads Anthropic settings as optional fields, DB schema includes all 10 analysis columns with migration support, BugRepository has store_analysis, store_analysis_message_id, and update_priority methods.</done>
</task>

<task type="auto">
  <name>Task 2: Create AI analysis service with Claude API integration</name>
  <files>
    src/services/__init__.py
    src/services/ai_analysis.py
  </files>
  <action>
**1. Create `src/services/__init__.py`** -- empty file (package marker).

**2. Create `src/services/ai_analysis.py`** -- the core AI service class.

The module should contain:

**`AIAnalysisService` class:**
```python
class AIAnalysisService:
    def __init__(self, api_key: str, model: str = "claude-haiku-4-5-20251001", max_tokens: int = 1024):
```
- Stores `self.client = AsyncAnthropic(api_key=api_key)`
- Stores `self.model` and `self.max_tokens`
- Sets `self.client` timeout to 60 seconds (not the default 600s) via the `timeout` parameter on AsyncAnthropic constructor
- Sets `max_retries=3` on the client constructor

**`analyze_bug(self, bug: dict) -> dict` async method:**
- Builds the system prompt via `_build_system_prompt()` (private method)
- Builds the user message via `_build_user_message(bug)` (private method)
- Calls `self.client.messages.create(model=self.model, max_tokens=self.max_tokens, system=system_prompt, messages=[{"role": "user", "content": user_message}])`
- Extracts `message.content[0].text`
- Parses the text via `_parse_response(text)` (private method)
- Attaches token usage: `result["usage"] = {"input_tokens": message.usage.input_tokens, "output_tokens": message.usage.output_tokens, "total_tokens": input + output}`
- Logs token usage at INFO level: `"AI analysis complete: {total} tokens ({input} in, {output} out)"`
- Returns the parsed dict

**`_build_system_prompt(self) -> str`:**
Use the system prompt from RESEARCH.md Pattern 4 verbatim. It instructs Claude to respond with ONLY a JSON object (no markdown, no code fences) with fields: root_cause, affected_area, severity, suggested_fix, priority, priority_reasoning. Includes the P1-P4 scoring rubric with weighted multi-factor criteria.

**`_build_user_message(self, bug: dict) -> str`:**
Build a message containing all available bug details:
```
Bug Report #{hash_id}

Title: {title or 'N/A'}
Description: {description or 'N/A'}
Severity (user-reported): {severity or 'N/A'}
Device: {formatted device_info}
App Version: {app_version or 'N/A'}
Steps to Reproduce: {steps_to_reproduce or 'N/A'}

Console Logs:
{formatted console_logs or 'None available'}
```
For device_info and console_logs, handle both string and JSON-serialized forms (same as embeds.py does). Import the `_parse_json_field` helper from `src.utils.embeds` or duplicate the logic locally (prefer import to stay DRY).

**`_parse_response(self, text: str) -> dict`:**
- First try `json.loads(text)` directly
- If that fails, strip markdown code fences: look for content between first `{` and last `}` and try `json.loads()` on that substring
- If still fails, log the raw response at ERROR level and raise `ValueError("Failed to parse AI response as JSON")`
- Validate that all required keys exist in the parsed dict: `root_cause`, `affected_area`, `severity`, `suggested_fix`, `priority`, `priority_reasoning`
- Normalize `severity` to lowercase
- Normalize `priority` to uppercase (P1, P2, P3, P4)
- If `priority` not in {"P1", "P2", "P3", "P4"}, default to "P3" and log a warning

**Error handling:** Do NOT catch `anthropic.APIError` subclasses in this service -- let them propagate to the caller (the Discord cog) which decides the UX response. Only catch JSON parsing errors internally.

**Imports needed:** `json`, `logging`, `anthropic` (AsyncAnthropic, and the error classes for type hints only), and optionally `_parse_json_field` from `src.utils.embeds`.
  </action>
  <verify>
- `python -c "from src.services.ai_analysis import AIAnalysisService; print('OK')"` succeeds
- `python -c "from src.services.ai_analysis import AIAnalysisService; s = AIAnalysisService.__new__(AIAnalysisService); result = s._parse_response('{\"root_cause\": \"test\", \"affected_area\": \"test\", \"severity\": \"high\", \"suggested_fix\": \"test\", \"priority\": \"P2\", \"priority_reasoning\": \"test\"}'); assert result['severity'] == 'high' and result['priority'] == 'P2'"` passes
- Verify markdown-stripping parse: `python -c "from src.services.ai_analysis import AIAnalysisService; s = AIAnalysisService.__new__(AIAnalysisService); r = s._parse_response('\`\`\`json\n{\"root_cause\":\"x\",\"affected_area\":\"x\",\"severity\":\"low\",\"suggested_fix\":\"x\",\"priority\":\"p4\",\"priority_reasoning\":\"x\"}\n\`\`\`'); assert r['priority'] == 'P4'"` passes
  </verify>
  <done>AIAnalysisService class exists with analyze_bug (calls Claude API, returns structured dict with usage), robust JSON parsing with markdown-fence stripping, system prompt with P1-P4 rubric, and user message builder that formats all bug fields.</done>
</task>

<task type="auto">
  <name>Task 3: Build analysis embed and update summary embed with priority badge</name>
  <files>src/utils/embeds.py</files>
  <action>
**1. Add severity colour mapping for analysis embeds** at module level in `src/utils/embeds.py`:
```python
SEVERITY_COLORS: dict[str, discord.Colour] = {
    "critical": discord.Colour(0xED4245),  # Red
    "high": discord.Colour(0xE67E22),       # Orange
    "medium": discord.Colour(0xF1C40F),     # Yellow
    "low": discord.Colour(0x2ECC71),        # Green
}
```
Note: This is DIFFERENT from STATUS_COLORS which maps bug *statuses*. SEVERITY_COLORS maps AI-assessed *severity levels* per user's locked decision for colour-coded sidebar.

**2. Create `build_analysis_embed(bug: dict, analysis: dict) -> discord.Embed`:**

This builds the analysis results embed posted in the bug's thread. Per CONTEXT.md locked decisions:
- Title: `"AI Analysis -- #{bug['hash_id']}"`
- Colour: sidebar colour from SEVERITY_COLORS based on `analysis["severity"]`
- Fields (all inline=False unless noted):
  - "Root Cause" -- `analysis["root_cause"]` (full paragraph, inline=False)
  - "Affected Area" -- `analysis["affected_area"]` (inline=True)
  - "Severity" -- `analysis["severity"].title()` (inline=True)
  - "Priority" -- `f"**{analysis['priority']}** -- {analysis['priority_reasoning']}"` (inline=False)
  - "Suggested Fix" -- `analysis["suggested_fix"]` (inline=False)
- Footer: `f"Analysis by Claude | {token_display}"` where token_display is `~{total/1000:.1f}k tokens` if >= 1000, else `~{total} tokens`
- Use `analysis["usage"]["total_tokens"]` for the token count

**3. Update `build_summary_embed(bug: dict) -> discord.Embed`:**

After the existing "Device" field, add a conditional priority field:
```python
priority = bug.get("priority")
if priority:
    embed.add_field(
        name="Priority",
        value=f"**{priority}**",
        inline=True,
    )
```
This adds the priority badge to the main channel embed for quick scanning, per the user's locked decision. Only shows when the bug has been analyzed (priority is not None).

This does NOT change the embed colour for analyzed bugs -- the status colour (triaged = orange) handles that via the existing STATUS_COLORS mapping.
  </action>
  <verify>
- `python -c "from src.utils.embeds import build_analysis_embed, SEVERITY_COLORS; print('OK')"` succeeds
- `python -c "from src.utils.embeds import build_analysis_embed; e = build_analysis_embed({'hash_id': 'abc123'}, {'root_cause': 'test', 'affected_area': 'auth', 'severity': 'high', 'suggested_fix': 'fix it', 'priority': 'P2', 'priority_reasoning': 'reason', 'usage': {'total_tokens': 1500}}); assert 'P2' in e.fields[3].value; assert '1.5k tokens' in e.footer.text"` passes
- `python -c "from src.utils.embeds import build_summary_embed; e = build_summary_embed({'hash_id': 'abc', 'status': 'triaged', 'priority': 'P1', 'created_at': '2026-01-01T00:00:00'}); field_names = [f.name for f in e.fields]; assert 'Priority' in field_names"` passes
  </verify>
  <done>build_analysis_embed produces a severity-coloured embed with root cause, affected area, severity, priority with reasoning, suggested fix, and token usage footer. build_summary_embed conditionally shows a priority badge field for analyzed bugs.</done>
</task>

</tasks>

<verification>
- All new imports resolve: `python -c "from src.services.ai_analysis import AIAnalysisService; from src.utils.embeds import build_analysis_embed, SEVERITY_COLORS; from src.models.bug import BugRepository; from src.config import Config; print('All imports OK')"`
- `pip install -r requirements.txt` succeeds with anthropic installed
- DB schema contains all 10 analysis columns
- AIAnalysisService._parse_response handles both clean JSON and markdown-wrapped JSON
- build_analysis_embed produces valid Discord embed with all required fields
- build_summary_embed shows priority field for analyzed bugs, omits it for unanalyzed bugs
</verification>

<success_criteria>
- anthropic SDK installed and importable
- Config loads ANTHROPIC_API_KEY (optional), ANTHROPIC_MODEL (default haiku-4.5), AI_MAX_TOKENS (default 1024)
- Database schema has 10 new analysis columns with migration support
- BugRepository has store_analysis, store_analysis_message_id, update_priority methods
- AIAnalysisService.analyze_bug calls Claude with structured prompt and returns parsed dict
- JSON parsing handles both clean responses and markdown-wrapped responses
- Analysis embed is colour-coded by severity with token usage footer
- Summary embed shows priority badge for analyzed bugs
</success_criteria>

<output>
After completion, create `.planning/phases/02-ai-analysis/02-01-SUMMARY.md`
</output>
